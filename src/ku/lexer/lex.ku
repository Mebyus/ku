import {
    tokens -> "ku/tokens"
}

pub
fun (&Lexer) lex(tok: &tokens.Token) {
	if g.eof() {
		g.emit_eof(tok);
        ret;
	}

	g.skip_whitespace_and_comments();
	if g.eof() {
		g.emit_eof(tok);
        ret;
	}

	g.emit(tok);
}

fun (&Lexer) emit_eof(tok: &tokens.Token) {
    tok.pin = g.pin();
    tok.kind = .EOF;
}

fun (&Lexer) emit(tok: &tokens.Token) {
	if g.peek() == 'c' && g.next() == '"' {
		g.emit_cstr(tok);
        ret;
	}

	if chars.is_latin_letter_or_underscore(g.peek()) {
		g.emit_word(tok);
        ret;
	}

	if chars.is_dec_digit(g.peek()) {
		g.emit_number(tok);
        ret;
	}

	if g.peek() == '"' {
		g.emit_str(tok);
        ret;
	}

    g.emit_other(tok);
}

fun (&Lexer) emit_cstr(tok: &tokens.Token) {
	g.advance();
	g.emit_str(tok);	
	tok.kind = .C_STRING;
}

fun (&Lexer) emit_word(tok: &tokens.Token) {

}

fun (&Lexer) emit_str(tok: &tokens.Token) {

}

fun (&Lexer) emit_number(tok: &tokens.Token) {
	if g.peek() != '0' {
		g.emit_dec_number(tok);
		ret;
	}

	if g.next() == 'x' {
		g.emit_hex_number(tok);
		ret;
	}
}

fun (&Lexer) emit_dec_number(tok: &tokens.Token) {
	tok.pin = g.pin();

}

fun (&Lexer) emit_hex_number(tok: &tokens.Token) {
	tok.pin = g.pin();

	g.advance(); // skip "0"
	g.advance(); // skip "x"

	g.start();
	g.skip_hex_digits();

	if chars.is_alphanum(g.peek()) {
		g.skip_word();
		data, ok := g.take();
		if ok {
			tok.set_error(.Malformed_Hex_Integer);
			tok.data.(lit) = data;
		} else {
			tok.set_error(.LENGTH_OVERFLOW);
		}
		ret;
	}

	if g.is_length_overflow() {
		tok.set_error(.LENGTH_OVERFLOW);
		ret;
	}
	if g.length() == 0 {
		tok.set_error(.Malformed_Hex_Integer);
		tok.data.(lit) = "0x";
		ret;
	}

	tok.kind = .INTEGER;
	if g.length() > 16 {
		stub;
		// lit, ok := g.take()
		// if !ok {
		// 	panic("unreachable due to previous checks")
		// }
		// tok.data.(lit) = lit;
		// ret;
	}

	tok.data.(val) = chars.parse_hex_digits(lx.View());
	ret;
}

fun (&Lexer) emit_other(tok: &tokens.Token) {
	if g.peek()
	-> '(' { g.emit_byte_token(tok, .LEFT_PAREN); }
	-> ')' { g.emit_byte_token(tok, .RIGHT_PAREN); }
	else { g.emit_illegal_byte(tok); }
}

fun (&Lexer) emit_byte_token(tok: &tokens.Token, kind: tokens.Kind) {
    tok.pin = g.pin();
    tok.kind = kind;
	
	g.advance();
}

fun (&Lexer) emit_illegal_byte(tok: &tokens.Token) {
	tok.pin = g.pin();

	g.advance();
}
